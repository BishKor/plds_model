{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import scipy.sparse as scsp\n",
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "from newton_method import nr_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kd(i,j):\n",
    "    if i == j:\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logposterior(y, C, d, A, B, q, q0, u, n_time_steps, n_neurons, n_stimuli_dims):\n",
    "    \"\"\"\n",
    "    :param y: neuron capture data\n",
    "    :param C: latent space to neuron space transformation matrix\n",
    "    :param d: mean firing rates\n",
    "    :param A: deterministic component of the evolution state[t] to state[t+1]\n",
    "    :param q: covariance of the innovations that perturb the latent state at each time step\n",
    "    :param q0: covariance of the initial state x1 of each trial\n",
    "    :param B: mapping of stimuli to \"latent space stimuli\"\n",
    "    :param u: stimuli (4-D one-hot)\n",
    "    :param n_time_steps: number of time steps\n",
    "    :param n_neurons: number of neurons\n",
    "    :return: the log-posterior of eq.4 in Macke et al. 2011\n",
    "    \"\"\"\n",
    "\n",
    "    def logpost(x):\n",
    "\n",
    "        # first compute useful values\n",
    "        q0inv = np.linalg.inv(q0)\n",
    "        qinv = np.linalg.inv(q)\n",
    "        \n",
    "        constants = .5 * (n_time_steps-1) * np.log(np.abs(np.linalg.det(q))) + .5 * np.log(np.abs(np.linalg.det(q0)))\n",
    "        term1 = sum(y[t*n_neurons:(t+1)*n_neurons].T @ (C @ x[t*nld:(t+1)*nld] + d) -\n",
    "                    np.sum(np.exp(C @ x[t*nld:(t+1)*nld] + d)) for t in range(n_time_steps-1))\n",
    "        term2 = - .5 * (x[1*nld:(1+1)*nld] - x[0*nld:(0+1)*nld]).T @ q0inv @ (x[1*nld:(1+1)*nld] - x[0*nld:(0+1)*nld])\n",
    "\n",
    "        term3 = - .5 * sum((x[(t+1)*nld:(t+2)*nld] -\n",
    "                    A @ x[t*nld:(t+1)*nld] -\n",
    "                    B @ u[t*n_stimuli_dims:(t+1)*n_stimuli_dims]).T @ qinv @ (x[(t+1)*nld:(t+2)*nld] -\n",
    "                    A @ x[t*nld:(t+1)*nld] -\n",
    "                    B @ u[t*n_stimuli_dims:(t+1)*n_stimuli_dims])\n",
    "                    for t in range(n_time_steps - 1))\n",
    "\n",
    "        return constants + term1 + term2 + term3\n",
    "\n",
    "    return logpost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logposteriorDerivative(y, C, d, A, B, q, q0, u, n_time_steps, n_neurons, n_stimuli_dims, nld):\n",
    "    def f(x):\n",
    "        df = np.empty_like(x)\n",
    "        Qinv = np.linalg.inv(q)\n",
    "        Q0inv = np.linalg.inv(q0)\n",
    "        for t in range(1, n_time_steps):\n",
    "            df[t*nld:(t+1)*nld] = sum((y[t*n_neurons:(t+1)*n_neurons][i] - np.exp(C[i]@x[t*nld:(t+1)*nld] + d[i]))*C[i] \n",
    "             for i in range(n_neurons)) + A.T @ Qinv @ (x[t*nld:(t+1)*nld] - A @ x[t*nld:(t+1)*nld] - B @ u[t*n_stimuli_dims:(t+1)*n_stimuli_dims]) \\\n",
    "            - Qinv @ (x[t*nld:(t+1)*nld] - A @ x[(t-1)*nld:t*nld] - B @ u[(t-1)*n_stimuli_dims:t*n_stimuli_dims]) \\\n",
    "            - kd(t, 1) * (Q0inv @ (x[1*nld:(1+1)*nld] - x[0*nld:(0+1)*nld]))\n",
    "        return df\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logposteriorHessian(y, C, d, A, B, q, q0, u, n_time_steps, n_neurons, n_stimuli_dims, nld):\n",
    "    def f(x):\n",
    "        h = np.zeros((n_time_steps*nld, n_time_steps*nld))\n",
    "        Qinv = np.linalg.inv(q)\n",
    "        Q0inv = np.linalg.inv(q0)\n",
    "        h[1*nld:(1+1)*nld, 1*nld:(1+1)*nld] += - Q0inv\n",
    "        \n",
    "        for t in range(1, n_time_steps-1):\n",
    "            h[t*nld:(t+1)*nld, t*nld:(t+1)*nld] += -sum(np.exp(C[i]*x[t*nld:(t+1)*nld] + d[i]) * np.outer(C[i], C[i].T) \n",
    "                                          for i in range(n_neurons)) + A.T @ Qinv @ A - Qinv\n",
    "            h[t*nld:(t+1)*nld, (t+1)*nld:(t+2)*nld] += - A.T @ Qinv\n",
    "            h[t*nld:(t+1)*nld, (t-1)*nld:t*nld] += - Qinv @ A\n",
    "            \n",
    "        h[n_time_steps*nld:(n_time_steps+1)*nld, n_time_steps*nld:(n_time_steps+1)*nld] += \\\n",
    "        -sum(np.exp(C[i]*x[n_time_steps*nld:(n_time_steps+1)*nld] + d[i]) * np.outer(C[i], C[i].T) for i in range(n_neurons)) \\\n",
    "        + A.T @ Qinv @ A - Qinv\n",
    "        h[n_time_steps*nld:(n_time_steps+1)*nld, (n_time_steps-1)*nld:n_time_steps*nld] += - Qinv @ A\n",
    "        return h\n",
    "    return f\n",
    "\n",
    "\n",
    "def logposteriorhessianoptomized(y, C, d, A, B, q, q0, u, n_time_steps, n_neurons, n_stimuli_dims, nld):\n",
    "    def f(x):\n",
    "        Qinv = np.linalg.inv(q)\n",
    "        Q0inv = np.linalg.inv(q0)\n",
    "        \n",
    "        diag = []\n",
    "        off_diag = []\n",
    "        diag.append(scsp.coo_matrix(-Q0inv))\n",
    "        ATQinvA = A.T @ Qinv @ A\n",
    "        ATQinv = A.T @ Qinv\n",
    "        QinvA = Qinv @ A\n",
    "        ATQinvAminusQinv = ATQinvA - Qinv\n",
    "        diag.append(- QinvA)\n",
    "        for t in range(0, n_time_steps-1):\n",
    "            \n",
    "            diag.append(scsp.coo_matrix(-sum(np.exp(C[i]*x[t*nld:(t+1)*nld] + d[i]) * np.outer(C[i], C[i].T) \n",
    "                                          for i in range(n_neurons)) + ATQinvAminusQinv))\n",
    "            off_diag.append(scsp.coo_matrix(-ATQinv))\n",
    "        \n",
    "        diag.append(scsp.coo_matrix(np.zeros_like(diag[0])))\n",
    "        h = scsp.block_diag(diag)\n",
    "        od = scsp.block_diag(off_diag)\n",
    "        h[n_time_steps:, :] = diag[:ntimesteps, :]\n",
    "        h[:, n_time_steps:] = diag[:, :ntimesteps]\n",
    "        return h\n",
    "    return f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "llph = logposteriorHessian(y, C, d, A, B, q, q0, u, n_time_steps, n_neurons, n_stimuli_dims, nld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-de520c3ff2f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-212-f9dac04f3d6a>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_time_steps\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             h[t*nld:(t+1)*nld, t*nld:(t+1)*nld] += -sum(np.exp(C[i]*x[t*nld:(t+1)*nld] + d[i]) * np.outer(C[i], C[i].T) \n\u001b[0;32m----> 9\u001b[0;31m                                           for i in range(n_neurons)) + A.T @ Qinv @ A - Qinv\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mQinv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mQinv\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-212-f9dac04f3d6a>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_time_steps\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             h[t*nld:(t+1)*nld, t*nld:(t+1)*nld] += -sum(np.exp(C[i]*x[t*nld:(t+1)*nld] + d[i]) * np.outer(C[i], C[i].T) \n\u001b[0;32m----> 9\u001b[0;31m                                           for i in range(n_neurons)) + A.T @ Qinv @ A - Qinv\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mQinv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnld\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mQinv\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tl = llph(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jllmake(y, n_stimuli_dims, n_neurons, n_time_steps, mu, cov, Q, Q0, x0, A, u, B):\n",
    "    def jointloglikelihood(dC):\n",
    "\n",
    "        d = np.empty(n_neurons)\n",
    "        C = np.empty((n_neurons, nld))\n",
    "\n",
    "        for i in range(n_neurons+1):\n",
    "            d[i] = dC[i*(nld+1)]\n",
    "            C[i] = dC[i*(nld+1) + 1:i*(nld+1)]\n",
    "\n",
    "        # precompute for efficiency\n",
    "        q0inv = np.linalg.inv(Q0)\n",
    "        qinv = np.linalg.inv(Q)\n",
    "\n",
    "        jll = sum(y[t*n_neurons:(t+1)*n_neurons].T @ C @ mu[t*nld:(t+1)*nld] \\\n",
    "                   + y[t*n_neurons:(t+1)*n_neurons].T @ d \\\n",
    "                   - .5 * np.exp(C @ mu[t*nld:(t+1)*nld] +\n",
    "                                 .5 * C.T @ cov[t*n_neurons:(t+1)*n_neurons, t*n_neurons:(t+1)*n_neurons] @ C + d) \\\n",
    "                   - .5 * mu[nld:2*nld].T @ q0inv @ mu[nld:2*nld] \\\n",
    "                   + .5 * np.trace(q0inv @ cov[nld:2*nld, 1*nld:2*nld]) \\\n",
    "                   + .5 * mu[nld:2*nld].T @ q0inv @ x0 \\\n",
    "                   + .5 * x0.T @ q0inv @ mu[nld:2*nld] \\\n",
    "                   - .5 * x0.T @ q0inv @ mu[nld:2*nld] \\\n",
    "                   - .5 * x0.T @ q0inv @ x0 \\\n",
    "                   - .5 * mu[(t+1)*nld:(t+2)*nld] @ q0inv @ mu[(t+1)*nld:(t+2)*nld] \\\n",
    "                   + np.trace(qinv @ cov[(t+1)*nld, (t+1)*nld]) \\\n",
    "                   + .5 * mu[(t+1)*nld:(t+2)*nld].T * qinv @ A @ mu[t*nld:(t+1)*nld] \\\n",
    "                   + np.trace(qinv @ A @ cov[t*nld:(t+1)*nld, (t+1)*nld:(t+2)*nld]) \\\n",
    "                   + .5 * mu[(t+1)*nld].T @ qinv @ B @ u[t*n_stimuli_dims:(t+1)*n_stimuli_dims] \\\n",
    "                   + .5 * mu[t*nld:(t+1)*nld].T @ A.T @ qinv @ mu[(t+1)*nld:(t+2)*nld] \\\n",
    "                   + np.trace(A @ qinv @ cov[(t+1)*nld:(t+2)*nld, t*nld:(t+1)*nld]) \\\n",
    "                   - .5 * mu[t*nld:(t+1)*nld].T @ A.T @ qinv @ A @ B @ u[t*n_stimuli_dims:(t+1)*n_stimuli_dims] \\\n",
    "                   + np.trace(A.T @ qinv @ A @ cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld]) \\\n",
    "                   - .5 * mu[t*nld:(t+1)*nld].T @ A.T @ qinv @ B @ u[t*n_stimuli_dims:(t+1)*n_stimuli_dims] \\\n",
    "                   + .5 * u[t*n_stimuli_dims:(t+1)*n_stimuli_dims].T @ B.T @ qinv @ mu[(t+1)*nld:(t+2)*nld] \\\n",
    "                   - .5 * u[t*n_stimuli_dims:(t+1)*n_stimuli_dims].T @ B.T @ qinv @ A @ mu[(t+1)*nld:(t+2)*nld] \\\n",
    "                   - .5 * u[t*n_stimuli_dims:(t+1)*n_stimuli_dims].T @ B.T @ qinv @ B @ u[t*n_stimuli_dims:(t+1)*n_stimuli_dims] for t in range(n_time_steps-1)) \\\n",
    "              - .5 * np.log(np.abs(np.det(Q0))) - .5 * (n_time_steps-1) * np.log(np.abs(np.det(Q)))\n",
    "\n",
    "        return jll\n",
    "    return jointloglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def laplace_approximation(f, df, Hf, mu):\n",
    "    # use NR algorithm to compute minimum of log-likelihood\n",
    "    mu = nr_algo(f, df, Hf, mu)\n",
    "\n",
    "    # negative inverse of Hessian is covariance matrix\n",
    "    covariance = -scsp.linalg.inv(H(mu))\n",
    "    return mu, covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jllDerivative(n_neurons, nld, mu, cov, n_time_steps, y):\n",
    "    def f(dC):\n",
    "        d = np.empty(n_neurons)\n",
    "        C = np.empty((n_neurons, nld))\n",
    "\n",
    "        for i in range(n_neurons+1):\n",
    "            d[i] = dC[i*(nld+1)]\n",
    "            C[i] = dC[i*(nld+1) + 1:i*(nld+1)]\n",
    "\n",
    "        djlld = sum(\n",
    "                y[t] + np.exp(C @ mu[t*nld:(t+1)*nld] + d + .5 * np.diag(C.T @ cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C))\n",
    "                for t in range(n_time_steps))\n",
    "\n",
    "        djllC = np.array([\n",
    "                sum(\n",
    "                y[t][i] * cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C[i] + mu[t] +\n",
    "                np.exp(C[i] @ mu[t*nld:(t+1)*nld] + d[i] + .5 * C[i] @ cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C[i]) *\n",
    "                (u[t] + cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C[i])\n",
    "                for t in range(n_time_steps))\n",
    "                for i in range(n_neurons)])\n",
    "\n",
    "        djlldC = np.array([np.concatenate(djlld[i], djllC[i]) for i in range(n_neurons)])\n",
    "        return djlldC\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jllHessian(n_neurons, nld, mu, cov, n_time_steps, y):\n",
    "    def f(dC):\n",
    "\n",
    "        d = np.empty(n_neurons)\n",
    "        C = np.empty((n_neurons, nld))\n",
    "\n",
    "        for i in range(n_neurons+1):\n",
    "            d[i] = dC[i*(nld+1)]\n",
    "            C[i] = dC[i*(nld+1) + 1:i*(nld+1)]\n",
    "\n",
    "        Hjll = np.zeros((n_neurons + n_neurons * nld, n_neurons + n_neurons * nld))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(n_neurons):\n",
    "            Hjll[i * (nld + 1), i * (nld + 1)] = sum(np.exp(C[i] @ mu[t*nld:(t+1)*nld] + d[i] +\n",
    "                                                    .5 * C[i] @ cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C[i])\n",
    "                                                    for t in range(n_time_steps))\n",
    "\n",
    "            Hjll[i * (nld + 1), i * (nld + 1) + 1:(i + 2) * (nld + 1)] = \\\n",
    "                sum((mu[t] + cov[t, t] @ C[i]) * np.exp(C[i] @ mu[t*nld:(t+1)*nld] + d[i] +\n",
    "                    .5 * C[i] @ cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C[i]) for t in range(n_time_steps))\n",
    "\n",
    "            Hjll[i * (nld + 1) + 1:(i + 2) * (nld + 1), i * (nld + 1)] = \\\n",
    "                Hjll[i * (nld + 1), i * (nld + 1) + 1:(i + 2) * (nld + 1)].T\n",
    "\n",
    "            Hjll[i * (nld + 1) + 1:(i + 2) * (nld + 1), i * (nld + 1) + 1:(i + 2) * (nld + 1)] = np.array([\n",
    "                sum(y[t][i] * cov[t, t] @ C[i] + mu[t] +\n",
    "                np.outer(mu[t] + cov[t, t] @ C[i], mu[t] + cov[t, t] @ C[i])[i] +\n",
    "                np.exp(C[i] @ mu[t*nld:(t+1)*nld] + d[i] + .5 * C[i] @ cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C[i]) *\n",
    "                (u[t] + cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C[i])\n",
    "                for t in range(n_time_steps))\n",
    "                ])\n",
    "        return Hjll\n",
    "    return f\n",
    "\n",
    "\n",
    "def jllHessianOptimized(n_neurons, nld, mu, cov, n_time_steps, y):\n",
    "    def f(dC):\n",
    "        d = np.empty(n_neurons)\n",
    "        C = np.empty((n_neurons, nld))\n",
    "\n",
    "        for i in range(n_neurons+1):\n",
    "            d[i] = dC[i*(nld+1)]\n",
    "            C[i] = dC[i*(nld+1) + 1:i*(nld+1)]\n",
    "\n",
    "        blocks = []\n",
    "        block = np.zeros((1 + nld)*(1 + nld)).reshape(-1, 1+nld)\n",
    "        \n",
    "        for i in range(n_neurons):\n",
    "            block[0, 0] = sum(np.exp(C[i] @ mu[t*nld:(t+1)*nld] + d[i] +\n",
    "                                                    .5 * C[i] @ cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C[i])\n",
    "                                                    for t in range(n_time_steps))\n",
    "\n",
    "            block[1, 1:] = sum((mu[t] + cov[t, t] @ C[i]) * np.exp(C[i] @ mu[t*nld:(t+1)*nld] + d[i] +\n",
    "                    .5 * C[i] @ cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C[i]) for t in range(n_time_steps))\n",
    "\n",
    "            block[1:, 1] = block[1, 1:].T\n",
    "\n",
    "            block[1:, 1:] = np.array([sum(y[t][i] * cov[t, t] @ C[i] + mu[t] +\n",
    "                np.outer(mu[t] + cov[t, t] @ C[i], mu[t] + cov[t, t] @ C[i])[i] +\n",
    "                np.exp(C[i] @ mu[t*nld:(t+1)*nld] + d[i] + .5 * C[i] @ cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C[i]) *\n",
    "                (u[t] + cov[t*nld:(t+1)*nld, t*nld:(t+1)*nld] @ C[i])\n",
    "                for t in range(n_time_steps))\n",
    "                ])\n",
    "        HJLL = scsp.\n",
    "        return Hjll\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BisharaKorkor/.virtualenvs/tf3/lib/python3.5/site-packages/ipykernel/__main__.py:20: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "n_time_steps = 26187\n",
    "n_neurons = 300  # number of neurons\n",
    "nld = 5  # number of latent dimensions\n",
    "n_stimuli_dims = 4\n",
    "frameHz = 10  # frames per seconds\n",
    "data = scio.loadmat('data/compiled_dF033016.mat')\n",
    "y = data['behavdF'].flatten()\n",
    "onset = data['onsetFrame'].T[0]\n",
    "resptime = data['resptime'].T[0]\n",
    "correct = data['correct'][0]\n",
    "orient = np.array(data['orient'][0], np.int)\n",
    "location = (data['location'][0]+1)//2\n",
    "\n",
    "# create empty u\n",
    "u = np.zeros((n_time_steps, n_stimuli_dims))\n",
    "# set stimuli\n",
    "for ot, rt, cor, ori, loc in zip(onset, resptime, correct, orient, location):\n",
    "    # compute what u should be here\n",
    "    u[ot:ot+int((rt+2.75+(4.85-2.75)*(1-cor))*frameHz)] = \\\n",
    "        np.array([ori*loc, (1-ori)*loc, ori*(1-loc), (1-ori)*(1-loc)], np.int)\n",
    "\n",
    "u = u.flatten()\n",
    "# Initialize parameters to random values\n",
    "C = np.random.randn(n_neurons* nld).reshape(-1, nld)\n",
    "d = np.random.randn(n_neurons)\n",
    "x0 = np.random.randn(nld)\n",
    "A = np.random.randn(nld * nld).reshape(-1, nld)\n",
    "q0 = np.abs(np.random.randn(nld * nld).reshape(-1, nld))\n",
    "q0 = q0@q0.T\n",
    "q = np.abs(np.random.randn(nld * nld).reshape(-1, nld))\n",
    "q = q@q.T\n",
    "B = np.random.randn(nld * n_stimuli_dims).reshape(-1, n_stimuli_dims)\n",
    "mu = np.random.randn(nld*n_time_steps)\n",
    "cov = np.random.randn(nld * nld).reshape(-1, nld)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
